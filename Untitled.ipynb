{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0b2c1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'yolov5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myolov5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'yolov5'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('yolov5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223200a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c71c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\prabh\\\\OneDrive\\\\Documents\\\\GitHub\\\\case_study_1\\\\yolov5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2f1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set up environment\n",
    "os.environ[\"DATASET_DIRECTORY\"] = os.path.join(os.getcwd(), \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea392c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets/smart-traffic-light-4 to yolov5pytorch: 100% [3145647 / 3145647] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets/smart-traffic-light-4 in yolov5pytorch:: 10\n"
     ]
    }
   ],
   "source": [
    "#after following the link above, recieve python code with these fields filled in\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"HDll2oFm5X8KK35ziZJL\")\n",
    "project = rf.workspace().project(\"casestudy1/smart-traffic-light\")\n",
    "dataset = project.version(\"4\").download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17162ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 416 --batch 16 --epochs 150 --data datasets/smart-traffic-light-4/data.yaml --weights yolov5s.pt --cache --freeze 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91160a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=datasets/smart-traffic-light-4/test/images/*.jpg, data=data\\coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-59-gfdc35b1 Python-3.10.8 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "image 1/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\18_png.rf.0b3bf6ca120cded41d5d9264c5e2736c.jpg: 416x416 1 person, 25 cars, 1 motorcycle, 205.6ms\n",
      "image 2/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\19_png.rf.c5c9d2dd880c2efcc4c91e787c083f14.jpg: 416x416 30 cars, 5 trucks, 1 traffic light, 177.5ms\n",
      "image 3/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\fire-engine-m25-motorway-on-emergency-call-to-road-accident-negotiating-C527YG_jpeg.rf.a38eaf15ef08369cd8fc6eefd3262a55.jpg: 416x416 1 person, 18 cars, 5 buss, 17 trucks, 150.1ms\n",
      "image 4/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\gettyimages-1166022385-594x594_jpeg.rf.9999d3a5bb99943796a64a5b49288f51.jpg: 416x416 5 persons, 10 cars, 2 trucks, 144.6ms\n",
      "image 5/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\high-wycombe-uk-27th-mar-2015-a-police-car-and-a-fire-engine-at-the-EJJG5B_jpeg.rf.1696c9ab26df082c46ac47f6bb73ba37.jpg: 416x416 9 cars, 1 truck, 179.1ms\n",
      "image 6/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\img4_png.rf.f6a327494c424307ddee894c9fc55512.jpg: 416x416 32 cars, 1 motorcycle, 3 buss, 4 trucks, 4 traffic lights, 198.1ms\n",
      "image 7/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\img5_jpeg.rf.11dbc89d70a88efa4a1d5b4d1aa66ca0.jpg: 416x416 2 persons, 9 cars, 1 bus, 19 trucks, 160.5ms\n",
      "image 8/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\img6_jpeg.rf.e67c87c51aecfdbb0b23fe8d2b1def51.jpg: 416x416 1 person, 31 cars, 2 trucks, 1 stop sign, 162.1ms\n",
      "image 9/9 C:\\Users\\prabh\\OneDrive\\Documents\\GitHub\\case_study_1\\yolov5\\datasets\\smart-traffic-light-4\\test\\images\\sample1_jpg.rf.7fd47bc2c4122c1281fad6529e80f8b6.jpg: 416x416 10 persons, 22 cars, 3 motorcycles, 5 trucks, 1 dog, 1 backpack, 149.5ms\n",
      "Speed: 1.2ms pre-process, 169.7ms inference, 4.1ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\detect\\exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --img 416 --conf 0.1 --source datasets/smart-traffic-light-4/test/images/*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565f00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('yolov5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3559bea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\prabh\\\\OneDrive\\\\Documents\\\\GitHub\\\\case_study_1\\\\yolov5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e830fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
